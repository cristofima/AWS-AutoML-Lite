# AWS AutoML Lite - Project Reference

## ğŸ“‘ Table of Contents

- [Project Overview](#-project-overview)
- [Architecture](#ï¸-architecture)
- [Technical Stack](#-technical-stack)
- [Project Structure](#-project-structure)
- [Data Flow](#-data-flow)
- [API Endpoints](#-api-endpoints)
- [Training Pipeline](#ï¸-training-pipeline)
- [Cost Analysis](#-cost-analysis)
- [Development Status](#-development-status)
- [Future Enhancements](#-future-enhancements)
- [Success Criteria](#-v100-success-criteria)
- [Technologies & Libraries](#-key-technologies--libraries)
- [Security Considerations](#-security-considerations)
- [References](#-references)

---

## ğŸ“‹ Project Overview

**Goal:** Build a lightweight AutoML platform on AWS that allows users to upload CSV files, automatically detect problem types (classification/regression), perform EDA, train models, and maintain training history.

**Target Audience:** AWS Community Builder article (Year 5 - Intermediate/Advanced level)

**Current Version:** v1.1.0 (December 2025)

**Timeline:** 1 week MVP âœ… Completed

**Key Differentiators from SageMaker Autopilot:**
- Lightweight and cost-effective
- Portable model export (pkl, ONNX)
- Simplified UX for rapid prototyping
- Educational focus
- No SageMaker Studio dependency

---

## ğŸ—ï¸ Architecture

### High-Level Architecture

![AWS AutoML Lite Architecture](./diagrams/architecture-main.png)

<details>
<summary>Text version</summary>

```
User â†’ AWS Amplify (Next.js SSR Frontend)
         â†“
    API Gateway â†’ Lambda Functions (FastAPI + Mangum)
         â†“
    DynamoDB (metadata/history) + S3 (files)
         â†“
    Lambda triggers AWS Batch Job
         â†“
    Batch (Fargate Spot) â†’ Train with FLAML
         â†“
    Save model to S3 + metrics to DynamoDB
```
</details>

### AWS Services Used

**Core Services (Must Have):**
- **S3**: Store datasets, trained models, EDA reports
- **DynamoDB**: Training history, metadata, job status
- **Lambda**: API endpoints (upload, list, get results)
- **API Gateway**: REST API
- **AWS Batch + Fargate Spot**: Async training for cost efficiency
- **CloudWatch**: Logs and metrics
- **IAM**: Granular roles per service

**Enhanced Services (Nice to Have):**
- **EventBridge**: Training completion events
- **X-Ray**: Distributed tracing
- **Systems Manager Parameter Store**: Configuration management
- **Step Functions**: (v2) Orchestrate ML pipeline

**Optional (Future):**
- **SageMaker Feature Store**: Store processed features
- **AWS Glue**: ETL for large datasets
- **SNS/SQS**: Async notifications

---

## ğŸ¯ Technical Stack

### Frontend
- **Framework**: Next.js 16+ (App Router)
- **Deployment**: AWS Amplify (auto-deploy from Git)
- **Build**: pnpm with SSR support
- **Key Features**:
  - CSV upload with drag & drop
  - Column selection UI
  - Training history dashboard
  - Results visualization with embedded reports

### Backend
- **Framework**: FastAPI + Mangum (for Lambda)
- **Runtime**: Python 3.11
- **Deployment**: Direct code (ZIP), no containers
- **Key Components**:
  - CSV parsing and validation
  - Auto problem type detection (classification/regression)
  - DynamoDB operations
  - S3 presigned URLs
  - Batch job triggering

**Size:** ~5MB compressed (fits in Lambda without containers)

### Training Pipeline
- **Container**: Docker on Fargate Spot (required - see why below)
- **ML Libraries**: FLAML, scikit-learn, XGBoost, LightGBM
- **EDA**: Sweetviz
- **Deployment**: Docker container (ECR)
- **Size:** ~265MB uncompressed (exceeds Lambda 250MB limit)
- **Runtime:** 2-60 minutes (exceeds Lambda 15min timeout)
- **Process**:
  1. Download CSV from S3
  2. Auto EDA generation
  3. Data preprocessing
  4. Model training with cross-validation
  5. Save model (.pkl) to S3
  6. Save metrics to DynamoDB
  7. Upload HTML report to S3

**Why containers?** Training requires large ML dependencies (265MB) and can take >15 minutes, both exceeding Lambda limits. See [ARCHITECTURE_DECISIONS.md](infrastructure/terraform/ARCHITECTURE_DECISIONS.md) for full analysis.

### Infrastructure as Code
- **Tool**: Terraform
- **Language**: HCL
- **Why Terraform**: Cross-platform compatible (Windows/Linux/Mac), industry standard, portable, better for multi-cloud future

---

## ğŸ“‚ Project Structure

```
aws-automl-lite/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app with Mangum
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py           # Upload endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ training.py         # Start/status training
â”‚   â”‚   â”‚   â”œâ”€â”€ datasets.py         # Dataset operations
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py           # Job management (CRUD, deploy)
â”‚   â”‚   â”‚   â””â”€â”€ predict.py          # Prediction endpoints (v1.1.0)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ s3_service.py       # S3 operations
â”‚   â”‚   â”‚   â”œâ”€â”€ dynamo_service.py   # DynamoDB operations
â”‚   â”‚   â”‚   â””â”€â”€ batch_service.py    # Batch job trigger
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ helpers.py          # Common utilities
â”‚   â”œâ”€â”€ training/                   # ğŸ‘ˆ Modular ML Package
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Package root
â”‚   â”‚   â”œâ”€â”€ main.py                 # Entry point (AWS Batch)
â”‚   â”‚   â”œâ”€â”€ Dockerfile              # Training container
â”‚   â”‚   â”œâ”€â”€ requirements.txt        # Training dependencies
â”‚   â”‚   â”œâ”€â”€ core/                   # Core ML components
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessor.py     # Data preprocessing
â”‚   â”‚   â”‚   â”œâ”€â”€ trainer.py          # FLAML training logic
â”‚   â”‚   â”‚   â””â”€â”€ exporter.py         # ONNX model export
â”‚   â”‚   â”œâ”€â”€ reports/                # Report generation
â”‚   â”‚   â”‚   â”œâ”€â”€ eda.py              # Auto EDA generation
â”‚   â”‚   â”‚   â””â”€â”€ training.py         # Training results report
â”‚   â”‚   â””â”€â”€ utils/                  # Shared utilities (DRY)
â”‚   â”‚       â””â”€â”€ detection.py        # Problem type detection
â”‚   â”œâ”€â”€ tests/                      # ğŸ‘ˆ Unit & Integration Tests
â”‚   â”‚   â”œâ”€â”€ pytest.ini              # Pytest configuration
â”‚   â”‚   â”œâ”€â”€ api/                    # API tests (104 tests)
â”‚   â”‚   â”‚   â”œâ”€â”€ conftest.py         # API test fixtures
â”‚   â”‚   â”‚   â”œâ”€â”€ test_endpoints.py   # Endpoint tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_schemas.py     # Pydantic schema tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_dynamo_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_s3_service.py
â”‚   â”‚   â”‚   â””â”€â”€ test_services_integration.py  # moto-based tests
â”‚   â”‚   â””â”€â”€ training/               # Training tests (159 tests)
â”‚   â”‚       â”œâ”€â”€ conftest.py         # Training test fixtures
â”‚   â”‚       â”œâ”€â”€ unit/               # Pure unit tests
â”‚   â”‚       â”‚   â”œâ”€â”€ test_preprocessor.py
â”‚   â”‚       â”‚   â”œâ”€â”€ test_column_detection.py
â”‚   â”‚       â”‚   â”œâ”€â”€ test_detect_problem_type.py
â”‚   â”‚       â”‚   â”œâ”€â”€ test_eda.py
â”‚   â”‚       â”‚   â””â”€â”€ test_training_report.py
â”‚   â”‚       â””â”€â”€ integration/        # Integration tests
â”‚   â”œâ”€â”€ requirements.txt            # API dependencies
â”‚   â””â”€â”€ requirements-dev.txt        # Testing dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                        # Next.js 16 App Router
â”‚   â”‚   â”œâ”€â”€ page.tsx                # Home/upload page
â”‚   â”‚   â”œâ”€â”€ configure/[datasetId]/  # Column selection
â”‚   â”‚   â”œâ”€â”€ training/[jobId]/       # Training status
â”‚   â”‚   â”œâ”€â”€ results/[jobId]/        # Results, deploy, playground
â”‚   â”‚   â”œâ”€â”€ compare/                # Model comparison (v1.1.0)
â”‚   â”‚   â””â”€â”€ history/                # Training history
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx          # Drag & drop upload
â”‚   â”‚   â”œâ”€â”€ Header.tsx              # Navigation with theme toggle
â”‚   â”‚   â”œâ”€â”€ ThemeToggle.tsx         # Dark/light mode
â”‚   â”‚   â”œâ”€â”€ JobMetadataEditor.tsx   # Tags & notes (v1.1.0)
â”‚   â”‚   â””â”€â”€ ColumnStatsDisplay.tsx  # Dataset stats (v1.1.0)
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts                  # API client
â”‚   â”‚   â”œâ”€â”€ useJobPolling.ts        # Job status polling
â”‚   â”‚   â””â”€â”€ utils.ts                # Utility functions
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ terraform/
â”‚       â”œâ”€â”€ main.tf                 # Provider & backend config
â”‚       â”œâ”€â”€ variables.tf            # Input variables
â”‚       â”œâ”€â”€ outputs.tf              # Output values
â”‚       â”œâ”€â”€ lambda.tf               # Lambda function
â”‚       â”œâ”€â”€ api_gateway.tf          # API Gateway
â”‚       â”œâ”€â”€ s3.tf                   # S3 buckets
â”‚       â”œâ”€â”€ dynamodb.tf             # DynamoDB tables
â”‚       â”œâ”€â”€ batch.tf                # AWS Batch
â”‚       â”œâ”€â”€ ecr.tf                  # ECR repository
â”‚       â”œâ”€â”€ iam.tf                  # IAM roles & policies
â”‚       â”œâ”€â”€ amplify.tf              # Amplify hosting
â”‚       â”œâ”€â”€ dev.tfvars              # Dev environment
â”‚       â”œâ”€â”€ prod.tfvars             # Prod environment
â”‚       â”œâ”€â”€ ARCHITECTURE_DECISIONS.md
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ scripts/
â”‚           â””â”€â”€ Dockerfile.lambda   # Lambda build artifact
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ QUICKSTART.md               # Deployment guide
â”‚   â”œâ”€â”€ PROJECT_REFERENCE.md        # This file
â”‚   â”œâ”€â”€ ROADMAP.md                  # Product roadmap
â”‚   â”œâ”€â”€ TECHNICAL_ANALYSIS.md       # Breaking changes analysis
â”‚   â”œâ”€â”€ LESSONS_LEARNED.md          # Challenges & solutions
â”‚   â”œâ”€â”€ UNIT_TESTING_ANALYSIS.md    # Testing strategy
â”‚   â””â”€â”€ diagrams/                   # Architecture diagrams
â”‚
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ copilot-instructions.md     # AI coding guidelines
â”‚   â”œâ”€â”€ SETUP_CICD.md               # CI/CD setup guide
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci-terraform.yml        # Terraform validation
â”‚       â”œâ”€â”€ deploy-infrastructure.yml
â”‚       â”œâ”€â”€ deploy-lambda-api.yml   # Includes API tests
â”‚       â”œâ”€â”€ deploy-training-container.yml  # Includes training tests
â”‚       â”œâ”€â”€ deploy-frontend.yml
â”‚       â””â”€â”€ destroy-environment.yml
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ CONTRIBUTING.md
â””â”€â”€ .gitignore
```

---

## ğŸ”„ Complete Workflow

![Data Flow](./diagrams/architecture-dataflow.png)

### 1. Upload Phase
```
User uploads CSV â†’ Frontend requests presigned URL from API
                â†’ Lambda generates presigned URL
                â†’ Frontend uploads directly to S3
                â†’ S3 event triggers Lambda
                â†’ Lambda analyzes CSV (columns, types, size)
                â†’ Lambda saves metadata to DynamoDB
                â†’ Returns dataset_id to frontend
```

### 2. Configuration Phase
```
Frontend fetches dataset metadata â†’ Displays columns
User selects target column â†’ Frontend calls /train endpoint
Lambda validates selection â†’ Detects problem type (classification/regression)
                          â†’ Creates training job record in DynamoDB
                          â†’ Triggers AWS Batch job
                          â†’ Returns job_id
```

### 3. Training Phase (Batch Container)

![Training Container Flow](./diagrams/architecture-training.png)

<details>
<summary>Text version</summary>

```
Batch job starts â†’ Downloads CSV from S3
               â†’ Generates EDA report (HTML)
               â†’ Preprocesses data (handling missing, encoding)
               â†’ Trains model with FLAML/AutoGluon
               â†’ Cross-validation
               â†’ Saves model (.pkl) to S3
               â†’ Saves metrics to DynamoDB
               â†’ Uploads EDA report to S3
               â†’ Updates job status to "completed"
               â†’ EventBridge emits completion event
```
</details>

### 4. Results Phase
```
Frontend polls status endpoint â†’ Lambda queries DynamoDB
Job completed â†’ Frontend fetches results
             â†’ Displays metrics (accuracy, F1, confusion matrix)
             â†’ Provides download links (model, report, EDA report)
             â†’ Feature importance available in downloadable Training Report HTML
```

---

## ğŸ“Š Data Models

### DynamoDB Table: training-jobs

**Primary Key:** `job_id` (String)

**Attributes:**
```json
{
  "job_id": "uuid",
  "dataset_id": "uuid",
  "user_id": "string",
  "created_at": "timestamp",
  "updated_at": "timestamp",
  "status": "pending|running|completed|failed",
  "dataset_name": "string",
  "target_column": "string",
  "problem_type": "classification|regression",
  "model_path": "s3://bucket/models/...",
  "report_path": "s3://bucket/reports/...",
  "metrics": {
    "accuracy": 0.95,
    "f1_score": 0.94,
    "training_time": 120.5
  },
  "tags": ["tag1", "tag2"],
  "notes": "string",  // Available in GET /jobs/{id}, not in LIST /jobs
  "deployed": true,
  "error_message": "string|null",
  "onnx_model_download_url": "string",
  "training_report_download_url": "string",
  "eda_report_download_url": "string"
}
```

**GSI:** `user_id-created_at-index` (for user history)

### DynamoDB Table: datasets

**Primary Key:** `dataset_id` (String)

**Attributes:**
```json
{
  "dataset_id": "uuid",
  "user_id": "string",
  "uploaded_at": "timestamp",
  "filename": "string",
  "s3_path": "s3://bucket/datasets/...",
  "size_bytes": 12345,
  "num_rows": 1000,
  "num_columns": 15,
  "columns": [
    {
      "name": "age",
      "dtype": "int64",
      "missing_pct": 0.05
    }
  ]
}
```

---

## ğŸš€ API Endpoints

### POST /upload
Request presigned URL for CSV upload

**Request:**
```json
{
  "filename": "data.csv",
  "content_type": "text/csv"
}
```

**Response:**
```json
{
  "dataset_id": "uuid",
  "upload_url": "presigned-s3-url",
  "expires_in": 3600
}
```

### POST /datasets/{dataset_id}/confirm
Confirm upload and trigger analysis

**Response:**
```json
{
  "dataset_id": "uuid",
  "status": "processing",
  "num_rows": 1000,
  "num_columns": 15,
  "columns": [...]
}
```

### POST /train
Start training job

**Request:**
```json
{
  "dataset_id": "uuid",
  "target_column": "price",
  "config": {
    "time_budget": 300,
    "metric": "auto"
  }
}
```

**Response:**
```json
{
  "job_id": "uuid",
  "status": "pending",
  "estimated_time": 180
}
```

### GET /jobs/{job_id}
Get training job status and results

**Response:**
```json
{
  "job_id": "uuid",
  "status": "completed",
  "problem_type": "regression",
  "metrics": {...},
  "model_download_url": "presigned-url",
  "report_download_url": "presigned-url"
}
```

### GET /jobs
List all training jobs (with pagination)

**Query Params:** `limit`, `next_token`

**Response:**
```json
{
  "jobs": [...],
  "next_token": "string|null"
}
```

### PATCH /jobs/{job_id}
Update job metadata (tags and notes)

**Request:**
```json
{
  "tags": ["experiment-1", "baseline"],
  "notes": "Initial model with default hyperparameters"
}
```

### DELETE /jobs/{job_id}
Delete training job and associated artifacts

**Query Params:** `delete_data=true|false`

### POST /jobs/{job_id}/deploy
Deploy or undeploy a trained model for inference

**Request:**
```json
{
  "deploy": true
}
```

**Response:**
```json
{
  "job_id": "uuid",
  "deployed": true,
  "message": "Model successfully deployed"
}
```

### POST /predict/{job_id}
Make predictions with a deployed model

**Request:**
```json
{
  "features": {
    "feature1": 10.5,
    "feature2": "category_a",
    "feature3": 100
  }
}
```

**Response (Classification):**
```json
{
  "job_id": "uuid",
  "prediction": "class_a",
  "probability": 0.85,
  "probabilities": {
    "class_a": 0.85,
    "class_b": 0.15
  },
  "inference_time_ms": 45.2,
  "model_type": "classification"
}
```

**Response (Regression):**
```json
{
  "job_id": "uuid",
  "prediction": 42.5,
  "probability": null,
  "inference_time_ms": 38.1,
  "model_type": "regression"
}
```

### GET /predict/{job_id}/info
Get model metadata for predictions (feature names, types, problem type)

**Response:**
```json
{
  "job_id": "uuid",
  "problem_type": "classification",
  "target_column": "Customer_Rating",
  "feature_columns": ["feature1", "feature2"],
  "feature_types": {
    "feature1": "numeric",
    "feature2": "categorical"
  },
  "categorical_mappings": {...},
  "deployed": true
}
```

---

## ğŸ’° Cost Analysis

### Estimated Monthly Costs (Moderate Usage)

**Assumptions:**
- 20 training jobs/month
- 10 GB total storage
- 100K API requests
- 10GB data transfer

**Breakdown:**
```
S3 Storage (10GB):              $0.23
S3 Requests:                    $0.05
DynamoDB (on-demand):           $1.00
Lambda (API - 100K invokes):    $0.80
API Gateway (100K requests):    $1.00
Batch + Fargate Spot:           $2-5 (depends on jobs)
Amplify (Frontend SSR):         $5-15 (depends on traffic)
CloudWatch Logs:                $0.50

Total: ~$2-15/month for moderate usage ($0 when idle).
```

**Comparison:**
- SageMaker with real-time endpoint: ~$36-171/month (t3.medium to c5.xlarge 24/7)
- Cost-Efficient: ~$2-15/month ($0 when idle) vs ~$36-171/month for SageMaker endpoints.
- **Savings: ~90-99%** (vs SageMaker with endpoints)

> Note: SageMaker training alone costs ~$0.68-3.20/month for 20 jobsâ€”comparable to this solution. The significant savings come from avoiding always-on inference endpoints.

---

## ğŸ§ª Testing Strategy

### Unit Tests
- Lambda handler functions
- Data preprocessing logic
- Problem type detection

### Integration Tests
- S3 upload/download
- DynamoDB operations
- Batch job triggering

### End-to-End Tests
- Complete workflow from upload to results
- Error handling scenarios

### Load Tests
- Concurrent uploads
- Multiple training jobs

---

## ğŸ“ˆ Future Enhancements

> ğŸ“‹ **Full roadmap:** See [ROADMAP.md](./ROADMAP.md) for detailed feature planning and timelines.

### v1.1.0 - Enhanced UX (Phase 2) âœ… Completed
- Serverless model inference (Lambda + ONNX Runtime)
- Model comparison dashboard
- Dark mode support
- ONNX model export
- Improved error handling

### v2.0.0 - Multi-user Platform (Phase 3)
- Cognito authentication
- Email notifications (SES)
- User workspaces
- Step Functions orchestration
- Advanced preprocessing options

---

## ğŸ“ Article Outline

### Title
"Building a Cost-Effective AutoML Platform on AWS: A Serverless Approach"

### Sections
1. **Introduction**
   - Problem: SageMaker Autopilot is powerful but expensive for prototyping
   - Solution: Lightweight serverless AutoML

2. **Architecture Overview**
   - Diagram
   - Service selection rationale
   - Cost comparison

3. **Implementation Deep Dive**
   - FastAPI + Lambda with Mangum
   - AWS Batch for training
   - DynamoDB for state management
   - Frontend with Next.js

4. **Key Learnings**
   - When to use Lambda vs Batch
   - Fargate Spot for cost savings
   - Serverless ML challenges

5. **Cost Analysis**
   - Detailed breakdown
   - Optimization tips

6. **Conclusion & Next Steps**
   - GitHub repo link
   - Future enhancements
   - Call to action

---

## ğŸ› ï¸ Development Status

### âœ… v1.0.0 - MVP Complete (December 3, 2025)

#### Backend Infrastructure âœ…
- [x] Terraform infrastructure (44 AWS resources)
- [x] S3 buckets with lifecycle policies
- [x] DynamoDB tables with GSI
- [x] IAM roles and policies
- [x] Lambda API with FastAPI + Mangum
- [x] API Gateway with REST endpoints
- [x] Training container (FLAML + ML libs)
- [x] AWS Batch integration (Fargate Spot)
- [x] CI/CD with GitHub Actions (OIDC)
- [x] S3 backend for Terraform state
- [x] Granular deployment workflows

#### Frontend âœ…
- [x] Next.js 16 project structure with App Router
- [x] Typed API client library
- [x] Upload page with drag & drop
- [x] Column selection & configuration
- [x] Training status page (polling)
- [x] Results page (metrics + download)
- [x] Training history table with pagination
- [x] Job deletion functionality
- [x] Deploy to AWS Amplify

#### Documentation âœ…
- [x] Complete project reference
- [x] Quick start deployment guide
- [x] Architecture decision records
- [x] Lessons learned document
- [x] CI/CD setup guide
- [x] Contributing guidelines
- [x] Changelog

### ğŸ“‹ Future Releases

See [ROADMAP.md](./ROADMAP.md) for detailed feature planning:
- **v1.1.0** - Enhanced UX & Serverless Inference (Phase 2) âœ…
- **v2.0.0** - Authentication & Notifications (Phase 3)

---

## ğŸ“š Key Technologies & Libraries

### Backend
```txt
fastapi==0.109.0
mangum==0.17.0
boto3==1.34.0
pydantic==2.5.0
python-multipart==0.0.6
```

### Training
```txt
flaml==2.1.0
pandas==2.1.4
scikit-learn==1.4.0
sweetviz==2.3.1
plotly==5.18.0
kaleido==0.2.1
joblib==1.3.2
```

### Frontend
```json
{
  "next": "16.x",
  "react": "19.x",
  "tailwindcss": "^4.x"
}
```

---

## ğŸ” Security Considerations

- S3 bucket policies (no public access)
- IAM least privilege principle
- Presigned URLs with expiration
- API Gateway throttling
- Input validation (CSV size, format)
- CloudWatch alarms for anomalies
- VPC for Batch jobs (optional)

---

## ğŸ“– References

- [AWS Batch Best Practices](https://docs.aws.amazon.com/batch/)
- [FastAPI on Lambda](https://mangum.io/)
- [FLAML Documentation](https://microsoft.github.io/FLAML/)
- [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/)
- [Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
- [GitHub Actions OIDC with AWS](https://docs.github.com/en/actions/security-for-github-actions/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services)

---

## ğŸ¯ v1.0.0 Success Criteria

**Technical:**
- Backend infrastructure deployed âœ…
- Cost under $25/month âœ… (Total: ~$2-15/month for moderate usage ($0 when idle).)
- CI/CD with GitHub Actions âœ…
- Lambda cold start < 2s âœ…
- Component-specific deployments âœ…
- Complete upload â†’ train â†’ download flow âœ…
- Training time < 5 minutes for small datasets âœ…

**Business:**
- Article published with working demo âœ…
- GitHub repo publicly available âœ…
- Production-ready deployment âœ…

---

**Last Updated:** 2025-12-24  
**Author:** Cristopher Coronado  
**Version:** v1.1.0  
**Status:** Released âœ…
